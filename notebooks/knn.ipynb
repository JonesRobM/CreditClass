{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbours for Credit Classification\n",
    "\n",
    "This notebook demonstrates k-Nearest Neighbours (k-NN) classification for credit default prediction using the UCI German Credit dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Overview\n",
    "\n",
    "**k-Nearest Neighbours (k-NN)** classifies instances based on the majority vote of their k closest neighbours in feature space.\n",
    "\n",
    "### Pros\n",
    "- Simple and intuitive algorithm\n",
    "- No training phase (lazy learner)\n",
    "- Naturally handles multi-class problems\n",
    "- Non-parametric (makes no assumptions about data distribution)\n",
    "- Can capture complex decision boundaries\n",
    "\n",
    "### Cons\n",
    "- Slow at inference time (must compute distances to all training points)\n",
    "- Sensitive to irrelevant features and feature scaling\n",
    "- High memory usage (stores all training data)\n",
    "- Performance degrades in high dimensions (curse of dimensionality)\n",
    "- Requires careful choice of k and distance metric\n",
    "\n",
    "### When to Use\n",
    "- When you need a simple baseline\n",
    "- For small to medium datasets\n",
    "- When interpretability at the instance level is important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from creditclass.preprocessing import prepare_data\n",
    "from creditclass.training import get_model, train_model, save_model, tune_hyperparameters\n",
    "from creditclass.evaluation import (\n",
    "    evaluate_model,\n",
    "    compute_shap_values,\n",
    "    get_learning_curve_data,\n",
    ")\n",
    "from creditclass.plots import (\n",
    "    set_plot_style,\n",
    "    plot_confusion_matrix,\n",
    "    plot_roc_curve,\n",
    "    plot_precision_recall,\n",
    "    plot_learning_curve,\n",
    "    plot_calibration,\n",
    "    plot_shap_summary,\n",
    ")\n",
    "\n",
    "set_plot_style()\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(\n",
    "    target_type='default',\n",
    "    encoding_method='onehot',\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    scale=True,  # k-NN requires scaling\n",
    ")\n",
    "\n",
    "X_train = data['X_train_scaled']\n",
    "X_test = data['X_test_scaled']\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model('knn')\n",
    "model = train_model(model, X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"Number of neighbours (k): {model.n_neighbors}\")\n",
    "print(f\"Weights: {model.weights}\")\n",
    "print(f\"Distance metric: {model.metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_model(model, X_test, y_test)\n",
    "\n",
    "print(\"Performance Metrics:\")\n",
    "print(\"-\" * 30)\n",
    "for name, value in metrics.items():\n",
    "    if value is not None:\n",
    "        print(f\"{name.capitalize():12} {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    model, X_test, y_test,\n",
    "    class_names=['Good Credit', 'Bad Credit'],\n",
    "    ax=axes[0],\n",
    "    title='k-NN - Confusion Matrix'\n",
    ")\n",
    "\n",
    "plot_roc_curve(model, X_test, y_test, ax=axes[1], label='k-NN')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "plot_precision_recall(model, X_test, y_test, ax=ax, label='k-NN')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of k\n",
    "\n",
    "Let's see how the choice of k affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [1, 3, 5, 7, 9, 11, 15, 21]\n",
    "k_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    knn = get_model('knn', params={'n_neighbors': k})\n",
    "    knn = train_model(knn, X_train, y_train)\n",
    "    metrics = evaluate_model(knn, X_test, y_test)\n",
    "    k_results.append({'k': k, **metrics})\n",
    "\n",
    "k_df = pd.DataFrame(k_results)\n",
    "print(k_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.plot(k_df['k'], k_df['accuracy'], 'o-', label='Accuracy')\n",
    "ax.plot(k_df['k'], k_df['f1'], 's-', label='F1')\n",
    "ax.plot(k_df['k'], k_df['auc'], '^-', label='AUC')\n",
    "\n",
    "ax.set_xlabel('k (Number of Neighbours)')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('k-NN Performance vs. k')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability\n",
    "\n",
    "k-NN provides instance-level interpretability through its neighbours. We can also use SHAP for global feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP values (using KernelExplainer)\n",
    "print(\"Computing SHAP values (this may take a moment)...\")\n",
    "shap_data = compute_shap_values(model, X_test, feature_names=feature_names, max_samples=50)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plot_shap_summary(shap_data, plot_type='bar', max_display=15)\n",
    "plt.title('k-NN - SHAP Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = tune_hyperparameters(\n",
    "    'knn',\n",
    "    X_train, y_train,\n",
    "    method='grid',\n",
    "    cv=5,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(tuning_results['best_params'])\n",
    "print(f\"\\nBest CV F1 Score: {tuning_results['best_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = tuning_results['best_model']\n",
    "tuned_metrics = evaluate_model(tuned_model, X_test, y_test)\n",
    "\n",
    "print(\"\\nTuned Model Performance:\")\n",
    "print(\"-\" * 30)\n",
    "for name, value in tuned_metrics.items():\n",
    "    if value is not None:\n",
    "        print(f\"{name.capitalize():12} {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_model = get_model('knn')\n",
    "lc_data = get_learning_curve_data(lc_model, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plot_learning_curve(lc_data, ax=ax, title='k-NN - Learning Curve')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 6))\n",
    "plot_calibration(model, X_test, y_test, ax=ax, label='k-NN')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = save_model(model, 'knn')\n",
    "print(f\"Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Simplicity**: k-NN is one of the simplest ML algorithms to understand\n",
    "2. **k Selection**: Choice of k significantly impacts bias-variance trade-off\n",
    "3. **Scaling**: Feature scaling is crucial for distance-based algorithms\n",
    "4. **Inference Cost**: Predictions require computing distances to all training points\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- Always scale features before using k-NN\n",
    "- Use cross-validation to select optimal k\n",
    "- Consider distance weighting for better performance\n",
    "- For large datasets, consider approximate nearest neighbour methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
